```
#### Secondary hypothesis tests, e.g trial order and age.
We will fit a linear mixed effects model predicting all individual observations, with the structure:\\
log(looking.time) ~ trial.num * stimulus * age + (trial.num * stimulus | subid) + (trial.num * stimulus * age | lab)\\
NB. This is taken from the RRR. Does stimulus here refer to condition or item? I have taken it to refer to condition.\\
Interactions removed to aid convergence.
```{r}
d_lmer3 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days),trial_numC = (trial_num - mean(trial_num))/sd(trial_num))
summary(lmer(log_lt ~ 1 + AgeC * trial_type * trial_numC + (1+ trial_type + trial_numC|subid)+ (1+ AgeC + trial_type + trial_numC|lab) , data = d_lmer3))
```
# Conclusions
Practical recommendations:
- Need to make standardized templates for `lab`, `subject`, and `trial` data.
- Need to develop policies for data exclusion at the subject level (e.g., any child excluded)
- Need to walk through and select the planned analyses - this is going to be tricky!
Conclusions: It looks like we're seeing some IDS preference for each group, albeit at a different part of the experiment for each age/lab combo.
options(dplyr.width = Inf)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, cache=TRUE)
library(lme4)
library(tidyverse)
library(eyetrackingR)
library(stringr)
library(lubridate)
library(bit64) # necessary because of times from SMI > max integer size
library(langcog)
library(knitr)
library(forcats)
source("et_helper.R")
theme_set(theme_bw())
raw_data_path <- "pilot/frank/"
info_path <- "info/"
processed_data_path <- "processed_data/frank/"
all_data <- dir(raw_data_path, pattern="*.txt") %>%
paste0(raw_data_path, .) %>%
map_df(get_smi_header) %>%
split(.$file_name) %>%
map_df(read_smi_idf) %>%
split(.$file_name) %>%
map_df(preprocess_data)
frank_data <- all_data %>%
group_by(file_name, trial, stimulus) %>%
summarise(looking_time = max(t_stim)) %>%
mutate(trial_cat = ifelse(str_detect(stimulus, ".jpg"), "speech","other")) %>%
filter(trial_cat == "speech") %>%
group_by(file_name) %>%
filter(trial > 5) %>%
mutate(trial_num = 1:n(),
subid = str_replace(str_replace(file_name,raw_data_path,""),
".txt",""))
info <- read_csv("info/frank_demo.csv")
frank_data <- info %>%
select(subid, age, order) %>%
left_join(frank_data)
orders <- read_csv("info/orders.csv") %>%
gather(marker, stimulus, 2:19) %>%
rename(order = Order) %>%
filter(!str_detect(stimulus, "Train")) %>%
group_by(order) %>%
mutate(trial_num = 1:n()) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = -2) %>%
select(-marker, -stim_num)
frank_data <- left_join(frank_data, orders) %>%
mutate(trial_num = ceiling(trial_num  / 2)) %>%
mutate(age_days = as.numeric(age),
lab = "stanford",
method = "eye-tracking") %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
floccia_data <- read_csv("pilot/floccia/pilot data.csv") %>%
rename(age_days = age,
looking_time = LT) %>%
mutate(subid = as.character(id),
method = "HPP",
stimulus = str_replace(str_replace(stimulus, ".wav", ""),
"Manybabies\\\\", "")) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = "-") %>%
mutate(trial_num = ceiling(trial/2)) %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
hamlin_path <- "pilot/hamlin/"
hamlin_data <- dir(hamlin_path, pattern="*.csv") %>%
paste0(hamlin_path, .) %>%
map_df(function(x) {read_csv(x) %>% mutate(order = x)}) %>%
mutate(order = as.numeric(str_replace(str_replace(order, ".csv",""),
"pilot/hamlin/order",""))) %>%
gather(trial, looking_time,
starts_with("Train"), starts_with("IDS"), starts_with("ADS")) %>%
separate(trial, into = c("trial_type","trial_num"), sep = -2) %>%
mutate(lab = "ubc",
method = "single-screen",
trial_num = as.numeric(trial_num),
age_days = str_split(age, ";") %>%
map_dbl(function(x) as.numeric(x[1]) * 30.3 + as.numeric(x[2]))) %>%
rename(subid = subnum) %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
d <- bind_rows(floccia_data, hamlin_data, frank_data)
kable(head(d))
d_t_test1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
t.test(d_t_test1$log_lt_diff , mu = 0)
d_lmer1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days))
summary(lmer(log_lt ~ 1 + AgeC * trial_type + (1+ AgeC + trial_type|lab), data = d_lmer1))
d_lmer1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days))
summary(lmer(log_lt ~ 1 + AgeC * trial_type + (1+ AgeC * trial_type|lab), data = d_lmer1))
orders <- read_csv("info/orders.csv") %>%
gather(marker, stimulus, 2:19) %>%
rename(order = Order) %>%
filter(!str_detect(stimulus, "Train")) %>%
group_by(order) %>%
mutate(trial_num = 1:n()) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = -2) %>%
select(-marker, -stim_num)
frank_data <- left_join(frank_data, orders) %>%
mutate(trial_num = ceiling(trial_num  / 2)) %>%
mutate(age_days = as.numeric(age),
lab = "stanford",
method = "eye-tracking") %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
info <- read_csv("info/frank_demo.csv")
frank_data <- info %>%
select(subid, age, order) %>%
left_join(frank_data)
frank_data <- all_data %>%
group_by(file_name, trial, stimulus) %>%
summarise(looking_time = max(t_stim)) %>%
mutate(trial_cat = ifelse(str_detect(stimulus, ".jpg"), "speech","other")) %>%
filter(trial_cat == "speech") %>%
group_by(file_name) %>%
filter(trial > 5) %>%
mutate(trial_num = 1:n(),
subid = str_replace(str_replace(file_name,raw_data_path,""),
".txt",""))
orders <- read_csv("info/orders.csv") %>%
gather(marker, stimulus, 2:19) %>%
rename(order = Order) %>%
filter(!str_detect(stimulus, "Train")) %>%
group_by(order) %>%
mutate(trial_num = 1:n()) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = -2) %>%
select(-marker, -stim_num)
frank_data <- left_join(frank_data, orders) %>%
mutate(trial_num = ceiling(trial_num  / 2)) %>%
mutate(age_days = as.numeric(age),
lab = "stanford",
method = "eye-tracking") %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
orders
frank_data
frank_data <- all_data %>%
group_by(file_name, trial, stimulus) %>%
summarise(looking_time = max(t_stim)) %>%
mutate(trial_cat = ifelse(str_detect(stimulus, ".jpg"), "speech","other")) %>%
filter(trial_cat == "speech") %>%
group_by(file_name) %>%
filter(trial > 5) %>%
mutate(trial_num = 1:n(),
subid = str_replace(str_replace(file_name,raw_data_path,""),
".txt",""))
frank_data
d
?C
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type,method,lab) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
d_moder1
contrasts(d_moder1$method)
d_moder1$method <- as.factor(d_moder1$method)
contrasts(d_moder1$method)
contrasts(d_moder1$method) <- contr.sum(3)
contrasts(d_moder1$method)
summary(lmer(log_lt_diff ~ method + (1|lab), data = d_moder1))
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type,method,lab) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
summary(lmer(log_lt_diff ~ method + (1|lab), data = d_moder1))
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type,method,lab) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
summary(lmer(log_lt_diff ~ method + (1|lab), data = d_moder1))
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time),AgeC = (age_days - mean(age_days))/sd(age_days)) %>%
group_by(subid,trial_type,method,lab,age_days) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab,age_days) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
summary(lmer(log_lt_diff ~ method*AgeC + (1+AgeC|lab), data = d_moder1))
d_moder1
load("~/GitHub/iPad_TurnTaking/DistrAnalyses/STAN_Analysis/Batch_Analysis/Expt1/expt1_kids.RDATA")
library(rstan)
print(eg_expt1_kids, pars = c("beta0","beta"))
print(eg_expt1_kids, pars = c("beta0","beta","beta_t0","beta_t","beta_s0","beta_s"))
load("~/GitHub/iPad_TurnTaking/DistrAnalyses/STAN_Analysis/Batch_Analysis/Expt1/expt1_adults.RDATA")
print(eg_expt1_adults, pars = c("beta0","beta","beta_t0","beta_t","beta_s0","beta_s"))
load("~/GitHub/iPad_TurnTaking/DistrAnalyses/STAN_Analysis/Batch_Analysis/Expt2/eg_expt2_child_unpred.RDATA")
library(rstan)
print(eg_expt2_child_unpred,pars=c("beta0","beta","beta_t0","beta_t","beta_s0","beta_s"))
setwd("~/Dropbox/Studies/Child_PsyLx/TopDown/Expt2_Words")
library(tidyverse)
library(lubridate)
library(ggplot2)
library(readr)
library(dplyr)
library(doBy)
## for bootstrapping 95% confidence intervals -- from Mike Frank https://github.com/langcog/KTE/blob/master/mcf.useful.R
library(bootstrap)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)} #  mean(x,na.rm=na.rm) -
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) } #- mean(x,na.rm=na.rm)}
read_TD_data <- function(csv,type){
word <- bind_rows(lapply(csv, read.csv, colClasses = c("birth_order"="character", "num_siblings"="character", "subject_id"="character")))
word$DOT <- parse_date_time(word$date_stamp, "%m/%d/%Y")
word$DOB <- parse_date_time(word$date_of_birth,c("%Y-%m-%d","%d/%m.%y"))
#word$age_weeks <- difftime(word$DOT,word$DOB,units = "weeks")
#word$age <- as.numeric(floor(word$age_weeks/26)/2)
#word <- subset(word, age > 1 & age <= 9)
#word$age <- ordered(word$age)
word$Experiment = type
word$trial_type <- as.factor(word$trial_type)
#word <- subset(word, trial_type == "critical" )
word$resp <- ifelse(word$accuracy == "true",1,0)
word$speaker_match <- as.factor(ifelse((word$plain == "fem_plain" & word$sws == "fem_sws")|(word$plain == "mal_plain" & word$sws == "mal_sws"),"Speaker Match","Speaker Mismatch"))
return(word)
}
student_data <- function(path,subject_list){
sine_words_csv <- dir(path = path,pattern='*.csv$', recursive = T,full.names = T)
sine_words <- read_TD_data(sine_words_csv,"Sine Words")
sine_words$testing_loc <- as.factor(sine_words$testing_loc)
sine_words<- subset(sine_words,trial_type == "critical")
sine_words <- subset(sine_words, testing_loc != "pilot")
sine_words$clarity <- as.factor(ifelse(sine_words$instruction_number %in% c(1,2),"clear","distorted"))
sine_words$novelty <- as.factor(ifelse(sine_words$distance %in% c("different"),"novel","familiar"))
sine_words$age <- NA
sine_words$lang <- NA
sine_words$choose_unmentioned <- ifelse(sine_words$chosen_pic == sine_words$sound1_item,0,ifelse(sine_words$chosen_pic == sine_words$sound2_item,0,1))
# Gradually Build a Wide dataframe for students to analyze
# Strategy is to build a series of by-participant data frames, and then merge them together
clarity <- sine_words %>%
select(subject_id,speaker_match,clarity,resp) %>%
group_by(subject_id,speaker_match, clarity) %>%
summarize(resp.mean = mean(resp)) %>%
spread(clarity,resp.mean)
novelty <- subset(sine_words, clarity == "distorted") %>%
select(subject_id,speaker_match,novelty,resp) %>%
group_by(subject_id,speaker_match, novelty) %>%
summarize(resp.mean = mean(resp)) %>%
spread(novelty,resp.mean)
unmentioned <- subset(sine_words, clarity == "distorted") %>%
select(subject_id,speaker_match,novelty,choose_unmentioned) %>%
group_by(subject_id,speaker_match, novelty) %>%
summarize(unmentioned.mean = mean(choose_unmentioned)) %>%
spread(novelty,unmentioned.mean)
distance <- subset(sine_words, clarity == "distorted" & novelty == "familiar") %>%
select(subject_id,speaker_match,distance,resp) %>%
group_by(subject_id,speaker_match, distance) %>%
summarize(resp.mean = mean(resp)) %>%
spread(distance,resp.mean)
dataframe <- merge(clarity, novelty, by = c("subject_id", "speaker_match"))
dataframe <- merge(dataframe, distance, by = c("subject_id", "speaker_match"))
dataframe <- merge(dataframe, unmentioned, by = c("subject_id", "speaker_match"), suffixes = c("",".unmentioned"))
subj_list <- read.csv(subject_list, header =  T)
dataframe <- merge(dataframe,subj_list, by = "subject_id")
return(dataframe)
}
adults <- student_data("./ITALIAN/","italian_subject_list.csv")
library(tidyverse)
library(lubridate)
library(ggplot2)
library(readr)
library(dplyr)
library(doBy)
## for bootstrapping 95% confidence intervals -- from Mike Frank https://github.com/langcog/KTE/blob/master/mcf.useful.R
library(bootstrap)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)} #  mean(x,na.rm=na.rm) -
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) } #- mean(x,na.rm=na.rm)}
read_TD_data <- function(csv,type){
word <- bind_rows(lapply(csv, read.csv, colClasses = c("birth_order"="character", "num_siblings"="character", "subject_id"="character")))
word$DOT <- parse_date_time(word$date_stamp, "%m/%d/%Y")
word$DOB <- parse_date_time(word$date_of_birth,c("%Y-%m-%d","%d/%m.%y"))
#word$age_weeks <- difftime(word$DOT,word$DOB,units = "weeks")
#word$age <- as.numeric(floor(word$age_weeks/26)/2)
#word <- subset(word, age > 1 & age <= 9)
#word$age <- ordered(word$age)
word$Experiment = type
word$trial_type <- as.factor(word$trial_type)
#word <- subset(word, trial_type == "critical" )
word$resp <- ifelse(word$accuracy == "true",1,0)
word$speaker_match <- as.factor(ifelse((word$plain == "fem_plain" & word$sws == "fem_sws")|(word$plain == "mal_plain" & word$sws == "mal_sws"),"Speaker Match","Speaker Mismatch"))
return(word)
}
student_data <- function(path,subject_list){
sine_words_csv <- dir(path = path,pattern='*.csv$', recursive = T,full.names = T)
sine_words <- read_TD_data(sine_words_csv,"Sine Words")
sine_words$testing_loc <- as.factor(sine_words$testing_loc)
sine_words<- subset(sine_words,trial_type == "critical")
sine_words <- subset(sine_words, testing_loc != "pilot")
sine_words$clarity <- as.factor(ifelse(sine_words$instruction_number %in% c(1,2),"clear","distorted"))
sine_words$novelty <- as.factor(ifelse(sine_words$distance %in% c("different"),"novel","familiar"))
sine_words$age <- NA
sine_words$lang <- NA
sine_words$choose_unmentioned <- ifelse(sine_words$chosen_pic == sine_words$sound1_item,0,ifelse(sine_words$chosen_pic == sine_words$sound2_item,0,1))
# Gradually Build a Wide dataframe for students to analyze
# Strategy is to build a series of by-participant data frames, and then merge them together
clarity <- sine_words %>%
select(subject_id,speaker_match,clarity,resp) %>%
group_by(subject_id,speaker_match, clarity) %>%
summarize(resp.mean = mean(resp)) %>%
spread(clarity,resp.mean)
novelty <- subset(sine_words, clarity == "distorted") %>%
select(subject_id,speaker_match,novelty,resp) %>%
group_by(subject_id,speaker_match, novelty) %>%
summarize(resp.mean = mean(resp)) %>%
spread(novelty,resp.mean)
unmentioned <- subset(sine_words, clarity == "distorted") %>%
select(subject_id,speaker_match,novelty,choose_unmentioned) %>%
group_by(subject_id,speaker_match, novelty) %>%
summarize(unmentioned.mean = mean(choose_unmentioned)) %>%
spread(novelty,unmentioned.mean)
distance <- subset(sine_words, clarity == "distorted" & novelty == "familiar") %>%
select(subject_id,speaker_match,distance,resp) %>%
group_by(subject_id,speaker_match, distance) %>%
summarize(resp.mean = mean(resp)) %>%
spread(distance,resp.mean)
dataframe <- merge(clarity, novelty, by = c("subject_id", "speaker_match"))
dataframe <- merge(dataframe, distance, by = c("subject_id", "speaker_match"))
dataframe <- merge(dataframe, unmentioned, by = c("subject_id", "speaker_match"), suffixes = c("",".unmentioned"))
subj_list <- read.csv(subject_list, header =  T)
dataframe <- merge(dataframe,subj_list, by = "subject_id")
return(dataframe)
}
italian <- student_data("./ITALIAN/","italian_subject_list.csv")
italian
library(tidyverse)
library(lubridate)
library(ggplot2)
library(readr)
library(dplyr)
library(doBy)
## for bootstrapping 95% confidence intervals -- from Mike Frank https://github.com/langcog/KTE/blob/master/mcf.useful.R
library(bootstrap)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)} #  mean(x,na.rm=na.rm) -
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) } #- mean(x,na.rm=na.rm)}
read_TD_data <- function(csv,type){
word <- bind_rows(lapply(csv, read.csv, colClasses = c("birth_order"="character", "num_siblings"="character", "subject_id"="character")))
word$DOT <- parse_date_time(word$date_stamp, "%m/%d/%Y")
word$DOB <- parse_date_time(word$date_of_birth,c("%Y-%m-%d","%d/%m.%y"))
#word$age_weeks <- difftime(word$DOT,word$DOB,units = "weeks")
#word$age <- as.numeric(floor(word$age_weeks/26)/2)
#word <- subset(word, age > 1 & age <= 9)
#word$age <- ordered(word$age)
word$Experiment = type
word$trial_type <- as.factor(word$trial_type)
#word <- subset(word, trial_type == "critical" )
word$resp <- ifelse(word$accuracy == "true",1,0)
word$speaker_match <- as.factor(ifelse((word$plain == "fem_plain" & word$sws == "fem_sws")|(word$plain == "mal_plain" & word$sws == "mal_sws"),"Speaker Match","Speaker Mismatch"))
return(word)
}
student_data <- function(path,subject_list){
sine_words_csv <- dir(path = path,pattern='*.csv$', recursive = T,full.names = T)
sine_words <- read_TD_data(sine_words_csv,"Sine Words")
sine_words$testing_loc <- as.factor(sine_words$testing_loc)
sine_words<- subset(sine_words,trial_type == "critical")
sine_words <- subset(sine_words, testing_loc != "pilot")
sine_words$clarity <- as.factor(ifelse(sine_words$instruction_number %in% c(1,2),"clear","distorted"))
sine_words$novelty <- as.factor(ifelse(sine_words$distance %in% c("different"),"novel","familiar"))
sine_words$age <- NA
sine_words$lang <- NA
sine_words$choose_unmentioned <- ifelse(sine_words$chosen_pic == sine_words$sound1_item,0,ifelse(sine_words$chosen_pic == sine_words$sound2_item,0,1))
# Gradually Build a Wide dataframe for students to analyze
# Strategy is to build a series of by-participant data frames, and then merge them together
clarity <- sine_words %>%
select(subject_id,speaker_match,clarity,resp) %>%
group_by(subject_id,speaker_match, clarity) %>%
summarize(resp.mean = mean(resp)) %>%
spread(clarity,resp.mean)
novelty <- subset(sine_words, clarity == "distorted") %>%
select(subject_id,speaker_match,novelty,resp) %>%
group_by(subject_id,speaker_match, novelty) %>%
summarize(resp.mean = mean(resp)) %>%
spread(novelty,resp.mean)
unmentioned <- subset(sine_words, clarity == "distorted") %>%
select(subject_id,speaker_match,novelty,choose_unmentioned) %>%
group_by(subject_id,speaker_match, novelty) %>%
summarize(unmentioned.mean = mean(choose_unmentioned)) %>%
spread(novelty,unmentioned.mean)
distance <- subset(sine_words, clarity == "distorted" & novelty == "familiar") %>%
select(subject_id,speaker_match,distance,resp) %>%
group_by(subject_id,speaker_match, distance) %>%
summarize(resp.mean = mean(resp)) %>%
spread(distance,resp.mean)
dataframe <- merge(clarity, novelty, by = c("subject_id", "speaker_match"))
dataframe <- merge(dataframe, distance, by = c("subject_id", "speaker_match"))
dataframe <- merge(dataframe, unmentioned, by = c("subject_id", "speaker_match"), suffixes = c("",".unmentioned"))
subj_list <- read.csv(subject_list, header =  T)
dataframe <- merge(dataframe,subj_list, by = "subject_id")
return(dataframe)
}
italian <- student_data("./ITALIAN/","italian_subject_list.csv")
italian
library(tidyverse)
library(lubridate)
library(ggplot2)
library(readr)
library(dplyr)
library(doBy)
## for bootstrapping 95% confidence intervals -- from Mike Frank https://github.com/langcog/KTE/blob/master/mcf.useful.R
library(bootstrap)
theta <- function(x,xdata,na.rm=T) {mean(xdata[x],na.rm=na.rm)}
ci.low <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.025,na.rm=na.rm)} #  mean(x,na.rm=na.rm) -
ci.high <- function(x,na.rm=T) {
quantile(bootstrap(1:length(x),1000,theta,x,na.rm=na.rm)$thetastar,.975,na.rm=na.rm) } #- mean(x,na.rm=na.rm)}
read_TD_data <- function(csv,type){
word <- bind_rows(lapply(csv, read.csv, colClasses = c("birth_order"="character", "num_siblings"="character", "subject_id"="character")))
word$DOT <- parse_date_time(word$date_stamp, "%m/%d/%Y")
word$DOB <- parse_date_time(word$date_of_birth,c("%Y-%m-%d","%d/%m.%y"))
#word$age_weeks <- difftime(word$DOT,word$DOB,units = "weeks")
#word$age <- as.numeric(floor(word$age_weeks/26)/2)
#word <- subset(word, age > 1 & age <= 9)
#word$age <- ordered(word$age)
word$Experiment = type
word$trial_type <- as.factor(word$trial_type)
#word <- subset(word, trial_type == "critical" )
word$resp <- ifelse(word$accuracy == "true",1,0)
word$speaker_match <- as.factor(ifelse((word$plain == "fem_plain" & word$sws == "fem_sws")|(word$plain == "mal_plain" & word$sws == "mal_sws"),"Speaker Match","Speaker Mismatch"))
return(word)
}
student_data <- function(path,subject_list){
sine_words_csv <- dir(path = path,pattern='*.csv$', recursive = T,full.names = T)
sine_words <- read_TD_data(sine_words_csv,"Sine Words")
sine_words$testing_loc <- as.factor(sine_words$testing_loc)
sine_words<- subset(sine_words,trial_type == "critical")
sine_words <- subset(sine_words, testing_loc != "pilot")
sine_words$clarity <- as.factor(ifelse(sine_words$instruction_number %in% c(1,2),"clear","distorted"))
sine_words$novelty <- as.factor(ifelse(sine_words$distance %in% c("different"),"novel","familiar"))
sine_words$age <- NA
sine_words$lang <- NA
sine_words$choose_unmentioned <- ifelse(sine_words$chosen_pic == sine_words$sound1_item,0,ifelse(sine_words$chosen_pic == sine_words$sound2_item,0,1))
# Gradually Build a Wide dataframe for students to analyze
# Strategy is to build a series of by-participant data frames, and then merge them together
clarity <- sine_words %>%
select(subject_id,speaker_match,clarity,resp) %>%
group_by(subject_id,speaker_match, clarity) %>%
summarize(resp.mean = mean(resp)) %>%
spread(clarity,resp.mean)
novelty <- subset(sine_words, clarity == "distorted") %>%
select(subject_id,speaker_match,novelty,resp) %>%
group_by(subject_id,speaker_match, novelty) %>%
summarize(resp.mean = mean(resp)) %>%
spread(novelty,resp.mean)
unmentioned <- subset(sine_words, clarity == "distorted") %>%
select(subject_id,speaker_match,novelty,choose_unmentioned) %>%
group_by(subject_id,speaker_match, novelty) %>%
summarize(unmentioned.mean = mean(choose_unmentioned)) %>%
spread(novelty,unmentioned.mean)
distance <- subset(sine_words, clarity == "distorted" & novelty == "familiar") %>%
select(subject_id,speaker_match,distance,resp) %>%
group_by(subject_id,speaker_match, distance) %>%
summarize(resp.mean = mean(resp)) %>%
spread(distance,resp.mean)
dataframe <- merge(clarity, novelty, by = c("subject_id", "speaker_match"))
dataframe <- merge(dataframe, distance, by = c("subject_id", "speaker_match"))
dataframe <- merge(dataframe, unmentioned, by = c("subject_id", "speaker_match"), suffixes = c("",".unmentioned"))
subj_list <- read.csv(subject_list, header =  T)
dataframe <- merge(dataframe,subj_list, by = "subject_id")
return(dataframe)
}
italian <- student_data("./ITALIAN/","italian_subject_list.csv")
italian
write.csv(italian, file = "adult_italians.csv")
